{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4d93f1",
   "metadata": {},
   "source": [
    "# Image Recognition - Model Training\n",
    "This notebook focuses on training a convolutional neural network (CNN) for the task of recognizing different models of \"things\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c196bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d869f",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "We load the data from local storage where images are organized into folders named after their respective classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f406c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path:  ../data/input\n",
      "Test path:  ../data/test\n",
      "Number of folders in input folder:  3\n"
     ]
    }
   ],
   "source": [
    "# Define transforms and data loader\n",
    "import os\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "base_path = '../data/'\n",
    "input_path = os.path.join(base_path, 'input')\n",
    "test_path = os.path.join(base_path, 'test')\n",
    "\n",
    "print(\"Input path: \", input_path)\n",
    "print(\"Test path: \", test_path)\n",
    "\n",
    "# Calculate the number of existing folder in input folder\n",
    "num_folders = len([folder for folder in os.listdir(input_path)])\n",
    "\n",
    "print(\"Number of folders in input folder: \", num_folders)\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=input_path, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Repeat for test data\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_path, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558ce93",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "We choose a simple CNN model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3146522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=87616, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../core/')  # Add the models directory to the Python path\n",
    "from simple_cnn import SimpleCNN\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleCNN(num_classes=num_folders)  # Here, 10 is the number of different classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "model.to(device)  # Move model to device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8565c0",
   "metadata": {},
   "source": [
    "## Model Compilation\n",
    "Setting up the loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3562676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Assuming model is already defined\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move criterion to device\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 10 == 9:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f64ac6",
   "metadata": {},
   "source": [
    "## Model Export\n",
    "Save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e075092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), '../build/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
